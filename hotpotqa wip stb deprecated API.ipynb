{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    " \n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "def llm_legacy(prompt, stop=[\"\\n\"]):\n",
    "    # response = openai.Completion.create(\n",
    "    response = openai.completions.create(\n",
    "      model=\"text-davinci-002\",\n",
    "      prompt=prompt,\n",
    "      temperature=0,\n",
    "      max_tokens=100,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.0,\n",
    "      stop=stop\n",
    "    )\n",
    "    return response.choices[0].text ##\n",
    "    # return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "def llm(prompt, stop=[\"\\n\"]):\n",
    "    response = openai.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=prompt,\n",
    "      temperature=0,\n",
    "      max_tokens=200,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.0,\n",
    "      stop=stop\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikienv, wrappers\n",
    "env = wikienv.WikiEnv()\n",
    "env = wrappers.HotPotQAWrapper(env, split=\"dev\")\n",
    "env = wrappers.LoggingWrapper(env)\n",
    "\n",
    "def step(env, action):\n",
    "    attempts = 0\n",
    "    while attempts < 10:\n",
    "        try:\n",
    "            return env.step(action)\n",
    "        except requests.exceptions.Timeout:\n",
    "            attempts += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for messages:\n",
    "```\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    "```\n",
    "\n",
    "Full documentation: https://platform.openai.com/docs/api-reference/chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_message(messages, role, content):\n",
    "    messages.append({\n",
    "        \"role\": role,\n",
    "        \"content\": content\n",
    "    })\n",
    "    return messages\n",
    "\n",
    "def get_one_message(messages, role=\"system\"):\n",
    "    final_message = \"\"\n",
    "    for message in messages:\n",
    "        if message[\"role\"] != role:\n",
    "            final_message += message[\"content\"] + \"\\n\"\n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "folder = './prompts/'\n",
    "prompt_file = 'prompts_naive.json'\n",
    "with open(folder + prompt_file, 'r') as f:\n",
    "    prompt_dict = json.load(f)\n",
    "\n",
    "webthink_examples = prompt_dict['webthink_simple6']\n",
    "instruction = \"\"\"Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types: \n",
    "(1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
    "(2) Lookup[keyword], which returns the next sentence containing keyword in the current passage.\n",
    "(3) Finish[answer], which returns the answer and finishes the task.\n",
    "Here are some examples.\n",
    "\"\"\"\n",
    "webthink_prompt = instruction + webthink_examples\n",
    "\n",
    "webthink_critique_examples = prompt_dict['webthink_critique_examples'] ##\n",
    "# instruction_critique = \"\"\"You are a helpful assistant. You are assisting another agent who's trying to solve a question answering task. You will find Thought, Action steps. Thought can reason about the current situation, and Action can be three types:\n",
    "# (1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
    "# (2) Lookup[keyword], which returns the next sentence containing the keyword in the current passage.\n",
    "# (3) Finish[answer], which returns the answer and finishes the task.\n",
    "# Ensure that the thoughts and actions are directed towards the most efficient and direct path to answer the given question, avoiding unnecessary steps or exhaustive searches.\n",
    "# Always include a Critique in your response. Suggest a new Thought, Action pair in the Critique only if corrections are necessary.\n",
    "# Be sure to not include indices or Observation when suggesting a new Thought, Action pair.\n",
    "# Here are some examples.\n",
    "# \"\"\" ##\n",
    "# instruction_critique = \"\"\"You are a helpful assistant. You are assisting another agent who's trying to solve a question answering task. Ensure that the thoughts and actions are directed towards the most correct and efficient path to answer the given question. You will find Thought, Action steps. Thought can reason about the current situation, and Action can be three types:\n",
    "# # (1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
    "# # (2) Lookup[keyword], which returns the next sentence containing the keyword in the current passage.\n",
    "# # (3) Finish[answer], which returns the answer and finishes the task.\n",
    "# Always include a Critique in your response. Suggest a new Thought, Action pair in the Critique only if corrections are necessary.\n",
    "# Be sure to not include indices of the type 1, 2, 3 after Thought or Action. Do not include new Observation.\n",
    "# Here are some examples.\n",
    "# \"\"\" ##\n",
    "instruction_critique = \"\"\"You are a helpful assistant. You are assisting another agent who's trying to solve a question answering task. Ensure that the thoughts and actions are directed towards the most correct and efficient path to answer the given question. You will find Thought, Action steps. Thought can reason about the current situation, and Action can be three types:\n",
    "# (1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
    "# (2) Lookup[keyword], which returns the next sentence containing the keyword in the current passage.\n",
    "# (3) Finish[answer], which returns the answer and finishes the task.\n",
    "Always include a Critique in your response. Suggest a new Thought, Action pair in the Critique only if corrections are necessary.\n",
    "Here are some examples.\n",
    "\"\"\" ##\n",
    "webthink_prompt_critique = instruction_critique + webthink_critique_examples ##\n",
    "\n",
    "def webthink(idx=None, prompt=webthink_prompt, to_print=True):\n",
    "# def webthink(messages, idx=None, to_print=True):\n",
    "    # print(\"START messages\", messages) ##\n",
    "    question = env.reset(idx=idx)\n",
    "    # question = \"What does the goddess associated with the goddess frigg consists of what tales?\" ##\n",
    "    if to_print:\n",
    "        print(idx, question)\n",
    "    prompt += question + \"\\n\"\n",
    "    # messages = append_message(messages, \"user\", question + \"\\n\") ##\n",
    "    n_calls, n_badcalls = 0, 0\n",
    "    for i in range(1, 8):\n",
    "        # time.sleep(5) ##\n",
    "        print(\"i\", i) ##\n",
    "        n_calls += 1\n",
    "        # messages_temp = messages.copy() ##\n",
    "        # if i == 1: ##\n",
    "        #     messages_temp[-1]['content'] += f\"Thought {i}:\" ##\n",
    "        # else: ##\n",
    "        #     messages_temp = append_message(messages_temp, \"user\", f\"Thought {i}:\") ##\n",
    "        # print(\"ONGOING messages\", messages) ##\n",
    "        thought_action = llm_legacy(prompt + f\"Thought {i}:\", stop=[f\"\\nObservation {i}:\"])\n",
    "        # thought_action = llm(messages_temp, stop=[f\"\\nObservation {i}:\"])\n",
    "        # print(\"thought_action\", thought_action) ##\n",
    "        try:\n",
    "            thought, action = thought_action.strip().split(f\"\\nAction {i}: \")\n",
    "            # if i != 1: ##\n",
    "            #     thought = thought.split(f\"Thought {i}: \")[1] ##\n",
    "        except:\n",
    "            print('ohh...', thought_action)\n",
    "            n_badcalls += 1\n",
    "            n_calls += 1\n",
    "            thought = thought_action.strip().split('\\n')[0]\n",
    "            # messages_temp[-1]['content'] = f\"Thought {i}: {thought}\\nAction {i}:\" ##\n",
    "            action = llm_legacy(prompt + f\"Thought {i}: {thought}\\nAction {i}:\", stop=[f\"\\n\"]).strip()\n",
    "            # time.sleep(5) ##\n",
    "            # action = llm(messages_temp, stop=[f\"\\n\"]).strip() ##\n",
    "\n",
    "        # TODO: critique the (Thought i, Action i) pair\n",
    "        # messages_critique = append_message([], \"system\", webthink_prompt_critique) ##\n",
    "        # messages_critique = append_message(messages_critique, \"user\", get_one_message(messages) + f\"Thought {i}: {thought}\\nAction {i}: {action}\") ##\n",
    "        # critique = llm(messages_critique, stop=None).strip() ## TODO: non fa la critica e si limita a ripetere il flow del ragionamento. Se fa correzzioni le copia da quelle proposte dall'agente principale\n",
    "        # if f\"Thought:\" in critique: ##\n",
    "        #     thought, action = critique.split(f\"\\nAction: \") ##\n",
    "        #     thought = thought.split(f\"Thought: \")[1] ##\n",
    "        #     thought = thought.replace(\"Thought:\", f\"Thought {i}:\") ##\n",
    "        #     action = action.replace(\"Action:\", f\"Action {i}:\") ##\n",
    "        # TODO: critique the (Thought i, Action i) pair\n",
    "\n",
    "        obs, r, done, info = step(env, action[0].lower() + action[1:])\n",
    "        obs = obs.replace('\\\\n', '')\n",
    "        step_str = f\"Thought {i}: {thought}\\nAction {i}: {action}\\nObservation {i}: {obs}\\n\"\n",
    "        prompt += step_str\n",
    "        # messages = append_message(messages, \"assistant\", step_str) ##\n",
    "        if to_print:\n",
    "            print(step_str)\n",
    "        if done:\n",
    "            break\n",
    "    if not done:\n",
    "        obs, r, done, info = step(env, \"finish[]\")\n",
    "    if to_print:\n",
    "        print(info, '\\n')\n",
    "    info.update({'n_calls': n_calls, 'n_badcalls': n_badcalls, 'traj': prompt}) ##\n",
    "    return r, info\n",
    "\n",
    "# import random\n",
    "# import time\n",
    "\n",
    "# random.seed(42)\n",
    "\n",
    "# idxs = list(range(7405))\n",
    "# random.Random(233).shuffle(idxs)\n",
    "\n",
    "# rs = []\n",
    "# infos = []\n",
    "# old_time = time.time()\n",
    "\n",
    "# for i in idxs[:1]:\n",
    "#     messages = append_message([], \"system\", webthink_prompt) ##\n",
    "#     r, info = webthink(messages, i, to_print=True)\n",
    "#     rs.append(info['em'])\n",
    "#     infos.append(info)\n",
    "#     print(sum(rs), len(rs), sum(rs) / len(rs), (time.time() - old_time) / len(rs))\n",
    "#     print('-----------')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3687 Question: What movie did actress Irene Jacob complete before the American action crime thriller film directed by Stuart Baird?\n",
      "i 1\n",
      "Thought 1: I need to search Irene Jacob and find the movie she completed before the American action crime thriller film directed by Stuart Baird.\n",
      "Action 1: Search[Irene Jacob]\n",
      "Observation 1: Irène Marie Jacob (born 15 July 1966) is a French-Swiss actress known for her work with Polish film director Krzysztof Kieślowski.[2] She won the 1991 Cannes Film Festival Award for Best Actress for the Kieślowski film The Double Life of Veronique, and was nominated for the BAFTA Award for Best Actress in a Leading Role for her 1994 film Three Colours: Red. Her other film appearances include The Secret Garden (1993), Beyond the Clouds (1995), U.S. Marshals (1998), and Eternity (2016).. Irène Jacob was born in Suresnes, Hauts-de-Seine, a western suburb of Paris.[3] The youngest child with three older brothers, she was raised in a highly educated and intellectual family and environment: her father, Maurice Jacob, was a physicist; her mother, a psychologist; one brother, Francis Jacob, a musician; and her other two brothers, scientists.[4][5] In 1969, at the age of three, Irène moved with her family to Geneva, Switzerland, where she became interested in the arts.. My family was very shy with feelings and never spoke about them, but we evolved a little bit.\n",
      "\n",
      "i 2\n",
      "Thought 2: The passage does not mention the movie Irene Jacob completed before the American action crime thriller film directed by Stuart Baird. Maybe I can look up \"before\".\n",
      "Action 2: Lookup[before]\n",
      "Observation 2: (Result 1 / 2) It was not something he talked about beforehand; he would only work on the set.\n",
      "\n",
      "i 3\n",
      "Thought 3: The movie Irene Jacob completed before the American action crime thriller film directed by Stuart Baird is Eternity.\n",
      "Action 3: Finish[Eternity]\n",
      "Observation 3: Episode finished, reward = 0\n",
      "\n",
      "\n",
      "{'steps': 3, 'answer': 'Eternity', 'gt_answer': 'Beyond the Clouds', 'question_idx': 3687, 'reward': False, 'em': False, 'f1': 0} \n",
      "\n",
      "0 1 0.0 3.1961328983306885\n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# random.seed(42) ##\n",
    "\n",
    "idxs = list(range(7405))\n",
    "random.Random(233).shuffle(idxs)\n",
    "\n",
    "rs = []\n",
    "infos = []\n",
    "old_time = time.time()\n",
    "\n",
    "for i in idxs[:1]:\n",
    "    # messages = append_message([], \"system\", webthink_prompt) ##\n",
    "    # r, info = webthink(messages, i, to_print=True) ##\n",
    "    r, info = webthink(i, to_print=True)\n",
    "    rs.append(info['em'])\n",
    "    infos.append(info)\n",
    "    print(sum(rs), len(rs), sum(rs) / len(rs), (time.time() - old_time) / len(rs))\n",
    "    print('-----------')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
